{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.28%\n",
      "Recall (macro avg): 71.28%\n",
      "Precision (macro avg): 71.60%\n",
      "F1 Score (macro avg): 71.18%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Dataset: Using the publicly available \"sentiment140\" dataset published by Stanford University for sentiment analysis.\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Sentiment140.tenPercent.sample.tweets.tsv', sep='\\t', header=None)\n",
    "df.columns = ['sentiment_label', 'tweet_text']\n",
    "\n",
    "# Filtering out the row with 'sentiment_label'\n",
    "df_cleaned = df[df['sentiment_label'] != 'sentiment_label']\n",
    "\n",
    "# Splitting the cleaned data into train and test sets\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(df_cleaned['tweet_text'], \n",
    "                                                                            df_cleaned['sentiment_label'], \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=42)\n",
    "\n",
    "# Vectorize the cleaned data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized_clean = vectorizer.fit_transform(X_train_clean)\n",
    "X_test_vectorized_clean = vectorizer.transform(X_test_clean)\n",
    "\n",
    "# Random Forest Model:\n",
    "# Ensemble learning method that fits a number of decision tree classifiers on various sub-samples of the dataset.\n",
    "# Uses averaging to improve the predictive accuracy and control overfitting.\n",
    "rf_model_cleaned = RandomForestClassifier(n_estimators=50, max_depth=20, min_samples_leaf=10, random_state=42)\n",
    "rf_model_cleaned.fit(X_train_vectorized_clean, y_train_clean)\n",
    "\n",
    "# Predicting on the cleaned test data\n",
    "y_pred_clean = rf_model_cleaned.predict(X_test_vectorized_clean)\n",
    "\n",
    "# Evaluating the model using the cleaned data\n",
    "accuracy_clean = accuracy_score(y_test_clean, y_pred_clean)\n",
    "report_clean = classification_report(y_test_clean, y_pred_clean, target_names=['Negative', 'Positive'], output_dict=True)\n",
    "\n",
    "recall_clean = report_clean['macro avg']['recall']\n",
    "precision_clean = report_clean['macro avg']['precision']\n",
    "f1_clean = report_clean['macro avg']['f1-score']\n",
    "\n",
    "print(f\"Accuracy: {accuracy_clean*100:.2f}%\")\n",
    "print(f\"Recall (macro avg): {recall_clean*100:.2f}%\")\n",
    "print(f\"Precision (macro avg): {precision_clean*100:.2f}%\")\n",
    "print(f\"F1 Score (macro avg): {f1_clean*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multi-layer Perceptron (MLP) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4000/4000 - 157s - loss: 0.6491 - accuracy: 0.6097 - recall: 0.6097 - precision: 0.6097 - val_loss: 0.5354 - val_accuracy: 0.7565 - val_recall: 0.7565 - val_precision: 0.7565 - 157s/epoch - 39ms/step\n",
      "Epoch 2/20\n",
      "4000/4000 - 149s - loss: 0.5286 - accuracy: 0.7571 - recall: 0.7571 - precision: 0.7571 - val_loss: 0.4742 - val_accuracy: 0.7824 - val_recall: 0.7824 - val_precision: 0.7824 - 149s/epoch - 37ms/step\n",
      "Epoch 3/20\n",
      "4000/4000 - 166s - loss: 0.4857 - accuracy: 0.7842 - recall: 0.7842 - precision: 0.7842 - val_loss: 0.4588 - val_accuracy: 0.7864 - val_recall: 0.7864 - val_precision: 0.7864 - 166s/epoch - 41ms/step\n",
      "Epoch 4/20\n",
      "4000/4000 - 133s - loss: 0.4616 - accuracy: 0.8022 - recall: 0.8022 - precision: 0.8022 - val_loss: 0.4548 - val_accuracy: 0.7863 - val_recall: 0.7863 - val_precision: 0.7863 - 133s/epoch - 33ms/step\n",
      "Epoch 5/20\n",
      "4000/4000 - 162s - loss: 0.4428 - accuracy: 0.8137 - recall: 0.8137 - precision: 0.8137 - val_loss: 0.4564 - val_accuracy: 0.7896 - val_recall: 0.7896 - val_precision: 0.7896 - 162s/epoch - 40ms/step\n",
      "Epoch 6/20\n",
      "4000/4000 - 151s - loss: 0.4222 - accuracy: 0.8237 - recall: 0.8237 - precision: 0.8237 - val_loss: 0.4628 - val_accuracy: 0.7859 - val_recall: 0.7859 - val_precision: 0.7859 - 151s/epoch - 38ms/step\n",
      "Epoch 7/20\n",
      "4000/4000 - 140s - loss: 0.4033 - accuracy: 0.8331 - recall: 0.8331 - precision: 0.8331 - val_loss: 0.4749 - val_accuracy: 0.7817 - val_recall: 0.7817 - val_precision: 0.7817 - 140s/epoch - 35ms/step\n",
      "Epoch 8/20\n",
      "4000/4000 - 137s - loss: 0.3819 - accuracy: 0.8428 - recall: 0.8428 - precision: 0.8428 - val_loss: 0.4911 - val_accuracy: 0.7765 - val_recall: 0.7765 - val_precision: 0.7765 - 137s/epoch - 34ms/step\n",
      "Epoch 9/20\n",
      "4000/4000 - 161s - loss: 0.3604 - accuracy: 0.8537 - recall: 0.8537 - precision: 0.8537 - val_loss: 0.5087 - val_accuracy: 0.7719 - val_recall: 0.7719 - val_precision: 0.7719 - 161s/epoch - 40ms/step\n",
      "Accuracy: 77.19%\n",
      "Recall: 77.19%\n",
      "Precision: 77.19%\n",
      "F1 Score: 77.19%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Dataset: Load and preprocess\n",
    "df = pd.read_csv('Sentiment140.tenPercent.sample.tweets.tsv', sep='\\t', header=None)\n",
    "df.columns = ['sentiment_label', 'tweet_text']\n",
    "df_cleaned = df[df['sentiment_label'] != 'sentiment_label']\n",
    "\n",
    "# Splitting data\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(df_cleaned['tweet_text'], \n",
    "                                                                            df_cleaned['sentiment_label'], \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=42)\n",
    "\n",
    "# Tokenizing and padding\n",
    "VOCAB_SIZE = 10000\n",
    "EMBEDDING_DIM = 32\n",
    "MAX_LENGTH = 100\n",
    "TRUNC_TYPE = 'post'\n",
    "PADDING_TYPE = 'post'\n",
    "OOV_TOKEN = '<OOV>'\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOKEN)\n",
    "tokenizer.fit_on_texts(X_train_clean)\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train_clean)\n",
    "train_padded = pad_sequences(train_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test_clean)\n",
    "test_padded = pad_sequences(test_sequences, padding=PADDING_TYPE, truncating=TRUNC_TYPE, maxlen=MAX_LENGTH)\n",
    "\n",
    "# Ensure labels are of integer type and then replace 4 with 1\n",
    "y_train_clean = y_train_clean.astype(int).replace({0:0, 4:1})\n",
    "y_test_clean = y_test_clean.astype(int).replace({0:0, 4:1})\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_train_encoded = to_categorical(y_train_clean, num_classes=2)\n",
    "y_test_encoded = to_categorical(y_test_clean, num_classes=2)\n",
    "\n",
    "# Multi-layer Perceptron (MLP) Model:\n",
    "mlp_model = Sequential([\n",
    "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
    "    Flatten(),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling with adjusted learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "mlp_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', Recall(name='recall'), Precision(name='precision')])\n",
    "\n",
    "# Training with early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "history_mlp = mlp_model.fit(train_padded, y_train_encoded, epochs=20, validation_data=(test_padded, y_test_encoded), callbacks=[early_stop], verbose=2)\n",
    "\n",
    "# Evaluating the model\n",
    "mlp_scores = mlp_model.evaluate(test_padded, y_test_encoded, verbose=0)\n",
    "print(f\"Accuracy: {mlp_scores[1]*100:.2f}%\")\n",
    "print(f\"Recall: {mlp_scores[2]*100:.2f}%\")\n",
    "print(f\"Precision: {mlp_scores[3]*100:.2f}%\")\n",
    "print(f\"F1 Score: {2*(mlp_scores[2]*mlp_scores[3])/(mlp_scores[2]+mlp_scores[3])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Metrics (Retrained):\n",
      "Accuracy: 77.99%\n",
      "Recall: 77.99%\n",
      "F1 Score: 77.99%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Sentiment140.tenPercent.sample.tweets.tsv', sep='\\t', header=None)\n",
    "df.columns = ['sentiment_label', 'tweet_text']\n",
    "\n",
    "# Filtering out the row with 'sentiment_label'\n",
    "df_cleaned = df[df['sentiment_label'] != 'sentiment_label']\n",
    "\n",
    "# Splitting the cleaned data into train and test sets\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(df_cleaned['tweet_text'], \n",
    "                                                                            df_cleaned['sentiment_label'], \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=42)\n",
    "\n",
    "# Vectorize the cleaned data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized_clean = vectorizer.fit_transform(X_train_clean)\n",
    "X_test_vectorized_clean = vectorizer.transform(X_test_clean)\n",
    "\n",
    "# Implementing the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logistic_model.fit(X_train_vectorized_clean, y_train_clean)\n",
    "\n",
    "# Predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test_vectorized_clean)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_logistic = accuracy_score(y_test_clean, y_pred_logistic)\n",
    "recall_logistic = recall_score(y_test_clean.astype(int).replace({0:0, 4:1}), (y_pred_logistic == '4').astype(int), average='macro')\n",
    "f1_logistic = f1_score(y_test_clean.astype(int).replace({0:0, 4:1}), (y_pred_logistic == '4').astype(int), average='macro')\n",
    "\n",
    "print(\"Logistic Regression Model Metrics (Retrained):\")\n",
    "print(f\"Accuracy: {accuracy_logistic*100:.2f}%\")\n",
    "print(f\"Recall: {recall_logistic*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_logistic*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Support Vector Machine (SVM) model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Metrics:\n",
      "Accuracy: 76.08%\n",
      "Recall: 76.08%\n",
      "F1 Score: 76.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Implementing the SVM model\n",
    "svm_model = LinearSVC(max_iter=10000, random_state=42)\n",
    "svm_model.fit(X_train_vectorized_clean, y_train_clean)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm_model.predict(X_test_vectorized_clean)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_svm = accuracy_score(y_test_clean, y_pred_svm)\n",
    "recall_svm = recall_score(y_test_clean.astype(int).replace({0:0, 4:1}), (y_pred_svm == '4').astype(int), average='macro')\n",
    "f1_svm = f1_score(y_test_clean.astype(int).replace({0:0, 4:1}), (y_pred_svm == '4').astype(int), average='macro')\n",
    "\n",
    "print(\"SVM Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_svm*100:.2f}%\")\n",
    "print(f\"Recall: {recall_svm*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_svm*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multinomial Naive Bayes model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Model Metrics:\n",
      "Accuracy: 76.62%\n",
      "Recall: 76.62%\n",
      "F1 Score: 76.56%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Implementing the Multinomial Naive Bayes model\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train_vectorized_clean, y_train_clean)\n",
    "\n",
    "# Predictions\n",
    "y_pred_mnb = mnb_model.predict(X_test_vectorized_clean)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_mnb = accuracy_score(y_test_clean, y_pred_mnb)\n",
    "recall_mnb = recall_score(y_test_clean.astype(int).replace({0:0, 4:1}), (y_pred_mnb == '4').astype(int), average='macro')\n",
    "f1_mnb = f1_score(y_test_clean.astype(int).replace({0:0, 4:1}), (y_pred_mnb == '4').astype(int), average='macro')\n",
    "\n",
    "print(\"Multinomial Naive Bayes Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_mnb*100:.2f}%\")\n",
    "print(f\"Recall: {recall_mnb*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_mnb*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
